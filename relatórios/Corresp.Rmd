---
title: "Indicador de correspondência"
output:
  html_document: default
  pdf_document: default
---
```{r, echo = FALSE, warning=FALSE, message=FALSE}
library(ggplot2)
library(tidyr)
library(tibble)
library(dplyr)
library(lubridate)
library(RColorBrewer)
library(ggrepel)
library(esquisse)
library(zoo)
library(forcats)
library(tidyverse)
library(gganimate)
library(gifski)
library(ggpubr)
library(animation)
library(patchwork)
library(padr)
library(xts)
```

```{r setup, include=FALSE, warning=FALSE, message=FALSE}
pdata<- read.csv("sgdc_anom.csv", sep = ",")
```

## Apresentação 

Este relatório apresenta resultados preliminares da amálise exploratória dos dados do Sistema de Gestão da Defesa Civil. Propõe-se a criação de um novo indicador que pode ser usado para avaliar a confiabilidade dos dados estudados bem como a eficiência dos canais de atendimento em triar as solicitações que entram no sistema. 

O indicador consiste em um número em (%), representando a fração das amastras em que o ocorrência indicada na solicitação (ocorr_solic) é igual à ocorrência observada em campo e registrada pelo técnico no momento da vistoria (ocorr_vist).


## Os dados 

Foram utilizados os regisstros do SGDC correspondentes ao período de 01/07/2004 a 31/12/2019, inicialmente contendo **147512 observações e 16 variáveis**. 

```{r,warning=FALSE, message=FALSE}
head(pdata)
```

### Filtragem

Para as análises pretendidas, o primeiro requisito é que fossem selecionadas apenas as solicitações que foram atendidas e que possuem um tipo de ocorrência registrado pelo técnico vistoriados. Assim, foram eliminadas as observações de acordo com o valor das variáveis:

Status da solicitação (desc_status): CANCELADO, BLOQUEADO, PENDENTE, NÃO VISUALIZADA e VISTORIA PROGRAMADA. 
Canal de abertura (orig_solic): ABERTA EM CAMPO, OFÍCIO e OUVIDORIA. 

Optou-se por suprimir as solicitações com orig_solic = _ABERTA EM CAMPO_ pois, como as solicitações são também abertas no momento da vistoria pelo técnico vistoriador, ocorr_solic e ocorr_vist devem, por regra, serem iguais, o que desbalancearia a amostra. 
As solicitações abertas via _OFÍCIO_ e _OUVIDORIA_ foram desconsideradas por fugirem do escopo de interesse da análise. 

```{r, warning=FALSE, message=FALSE}
pdata <- pdata[!(pdata$desc_status == "CANCELADO"),]
pdata <- pdata[!(pdata$desc_status == "BLOQUEADO"),]
pdata <- pdata[!(pdata$desc_status == "PENDENTE"),]
pdata <- pdata[!(pdata$desc_status == "NÃO VISUALIZADA"),]
pdata <- pdata[!(pdata$desc_status == "VISTORIA PROGRAMADA"),]
pdata <- pdata[!(pdata$desc_orig_solic == "ABERTA EM CAMPO"),]
pdata <- pdata[!(pdata$desc_orig_solic == "OFICIO"),]
pdata <- pdata[!(pdata$desc_orig_solic == "OUVIDORIA"),]
pdata <- pdata[!(pdata$ocorr_vist == "NULL"),]


```

Também para facilitar a análise, as ocorrências _AVLIAÇÃO DE IMÓVEL ALAGADO_, _ALAGAMENTO DE IMÓVEL_ e _ALAGAMENTO DE IMÓVE_ foram sintetizadas em um único tipo _ALAGAMENTO_. 

### Modelagem

```{r, warning=FALSE, message=FALSE}
alagamentos <- c("AVALIAÇÃO DE IMÓVEL ALAGADO", "ALAGAMENTO DE IMÓVEL", "ALAGAMENTO DE ÁREA")
pdata$ocorr_solic <- ifelse(pdata$ocorr_solic %in% alagamentos, "ALAGAMENTO", pdata$ocorr_solic)
pdata$ocorr_vist <- ifelse(pdata$ocorr_vist %in% alagamentos, "ALAGAMENTO", pdata$ocorr_vist)

```

Por fim, criamos uma nova coluna no dataset, que deverá ter valor VERDADEIRO ( _TRUE_ ) se a ocorrência indicada na solicitação e a observada na vistoria coincidirem e FALSO ( _FALSE_ ) caso sejam diferentes. 

O conjunto de dados final contem 88.760 observações e 17 variáveis. 

```{r, echo = FALSE, , warning=FALSE, message=FALSE}
sdata <- pdata %>% mutate(match = ifelse(ocorr_solic == ocorr_vist, TRUE, FALSE))
head(sdata)
```

## Análises
### Univariada
O valor de C para cada ocorrência pode ser obsevado no gráfico a seguir. Observa-se que quatro ocorrências críticas, que exigem uma resposta imediata da Defesa Civil e demais órgãos do SMPDC, mostram valores entre 50% e 60%, enquanto outras três do tipo ficam abaixo dos 40%. 
Podemos dizer a partir daí que uma solicitação aberta como **deslizamento de terra** tem uma chance aproximada de 50% de **não** ser um deslizamento de terra real, as mesmas chances de tirar um "cara" ao lançar uma moeda. 

```{r, echo=FALSE, warning=FALSE, message=FALSE}
prop <- sdata %>%  group_by(ocorr_solic) %>% 
                   summarise(C = mean(match)*100)

ocorr_emerg = c("DESLIZAMENTO DE TERRA", "DESABAMENTO DE IMOVEL", "DESABAMENTO DE MURO", "EXPLOSAO",
                 "PISTA ROMPIDA", "ARVORE CAIDA", "DESABAMENTO PARCIAL")
delete <- c("VAZAMENTO DE GÁS", "ORIENTAÇÃO TÉCNICA", "AVALIACAO DA AREA", "ARMAZENAMENTO DE MATERIAIS PERIGOSOS", "DESABAMENTO DE BLOCOS DE UMA PEDREIRA" )

prop_2 <- filter(prop, !(ocorr_solic %in% delete))%>%  
  mutate(name = fct_reorder(ocorr_solic, C)) %>%  
  mutate(resp = ifelse(ocorr_solic %in% ocorr_emerg, "Crítico", "Preventivo")) 
prop_2 <- prop_2[order(-prop_2$C ),]

prop_2 %>%      ggplot() + geom_bar(aes(x = name, y= C, fill = resp), stat = "identity") +
                               geom_text(aes(x=ocorr_solic, y = C, hjust = -0.1, label = paste0(round(C,1), "%")))+
                               scale_fill_manual(values = c("#3568ab", '#d9d9d9')) +
                               geom_hline(yintercept = 50,  color = "red", linetype = "dashed", size=0.9)+
                               theme_grey() +
                               coord_flip() +
                               theme(legend.position = "none")+
                               labs(title = "Indicador de correspondência (C) por tipo de ocorrência",
                                    caption = "Período analisado: 07/05/2020 a 31/12/2019. 
                                               Total de observações: 88760", 
                                    x = "Ocorrência",
                                    y = "C") 
```
É possível também, a partir desta primeira análise, investigar quais são as situações reais observadas pelo técnico em campo quando, não são as ocorrências indicadas no momento da abertura do chamado. Abaixo, temos a tabela com essas informações para as ocorrências destacadas no gráfico anterior. 

```{r, echo=FALSE, warning=FALSE, message=FALSE}

prop_3 <- sdata[sdata$ocorr_solic %in% ocorr_emerg,] %>% group_by(ocorr_solic, ocorr_vist) %>% 
          summarise(n = n()) %>% 
          mutate(freq = n/sum(n)*100) %>%
          arrange(-freq, .by_group = TRUE) %>% 
          mutate(ocorr_vist = factor(ocorr_vist, levels = ocorr_vist)) %>% 
          select(-c(n)) %>% 
          as.data.frame()

 
```
Calculando essa tabela para _ORITENTAÇÃO TÉCNCIA_, um tipo de ocorrência coringa dentro do sistema, selecionado quando a ocorrência observada não se encaixa em nenhuma das tipologias disponíveis, observamos que aproximadamente 1/4 das solicitações são indicadas posteriormente pelo técnico como _AMEAÇA DE DESABAMENTO_. A maior parte é classidicada tanbém como _ORIENTAÇÃO TÉCNICA_, o que abre espaço para novas análises mais aprofundadas para verificar, talvez a partir das intervenções indicadas, se são atendimentos que fogem do escopo da Defesa Civil, ou mesmo identificar novas tipologias a serem inseridas na lista de ocorrências. 

```{r, echo=FALSE, warning=FALSE, message=FALSE}

sdata[sdata$ocorr_solic == "ORIENTAÇÃO TÉCNICA",] %>% group_by(ocorr_vist) %>% 
          summarise(n = n()) %>% 
          mutate(freq = n/sum(n)*100) %>% 
          arrange(-freq)

          

```
### Multivariada 

Nesta seção dispomos as observações feitas a partir do cruzamento do Indicador (C) com outras variáveis, como canal de ocorrência, data de abertura do chamado e local. 

#### Qauntidade de solicitações e data de abertura

Buscando investigar se o número de solicitações que entram por dia interfete no Valor de C, traçamos um gráfico de dispersão relacionado ambas as variáveis para _DESLIZAMENTO DE TERRA_. 

Observamos inicialmente que dias com menos que 10 solicitações apresentam uma variação muito grande e não indicam quaisquer tendência. Contudo, quando consideramos os dias com mais de 100 solicitações, é possível identificar uma correlação positiva: dias com muitas solicitações tendem a ter um valor de C maior. 
Usando o coeficiente de correlação linear de Pearson para quantificar essa correlação, obtemos **r = 0.490569**, indicador que existe uma relação positiva de média intensidade entre as duas variáveis. O p-valor = 0.002772 < 0.05 indica que esta é uma estatísitca significativa.  

```{r, echo=FALSE, warning=FALSE, message=FALSE}

os_dt = c("DESLIZAMENTO DE TERRA", "AMEACA DE DESLIZAMENTO")
os_db = c("DESABAMENTO DE IMOVEL", "AMEACA DE DESABAMENTO")


dt <- sdata[sdata$ocorr_solic %in% os_dt,] %>% group_by(year(data_solic), date(data_solic), ocorr_solic) %>% 
                                          summarise(n_solic = n(), C = mean(match)) %>% 
                                          filter(n_solic >= 10, `year(data_solic)` >= 2005, ocorr_solic == "DESLIZAMENTO DE TERRA") 

#Gráfico de dispersão
dt %>%  ggplot(aes(x=n_solic, y=C)) + geom_point()+ ylim(0,1)+
        stat_smooth(method =  "lm", col = "red")+ #facet_wrap(~ocorr_solic)+ 
        labs(title = "Gráfico de dispersão: número de solicitações (n_solic) x indicador (C)",
         subtitle = "Deslizamentos de terra. n de corte = 100", 
         x = "número de solicitações", 
         y = "indicador") 

summary(dt)
cor(dt$n_solic, dt$C, method = c("pearson"))
cor.test(dt$n_solic, dt$C, method = c("pearson"))
```
#### Caracterização da distribuição e testes de normalidade. 

A convergência para um valor à medida que o número de solicitações aumenta aponta que C, interpretada como uma variável aleatória, deve seguir uma distribuição de probabilidade normal. Para confirmar tal hipótese, faremos análises gráficas e testes estatísticos. 

OS gráficos de boxplot, histograma e q-q plot nos dão uma noção visual do formato da distribuição. 
```{r, animation.hook='gifski', echo=FALSE, warning=FALSE, message=FALSE, fig.align = 'center'}
dt_h <- sdata[sdata$ocorr_solic == "DESLIZAMENTO DE TERRA",]
dt_ts <- dt_h %>%mutate(data_solic = ymd_hms(data_solic)) %>% 
  mutate(datahora_solic = floor_date(data_solic,unit = "hour")) %>% 
  group_by(datahora_solic) %>% 
  summarise(n_solic = n(), n_true = sum(match)) %>% 
  as.xts()

aggregate(dt_ts, by=day, sum())


dt_ts<- dt_ts %>%  thicken("3 hour") %>% group_by(datahora_solic_3_hour) %>% summarise(sum(n_solic), sum(n_true)) %>% 
                                 mutate(C = `sum(n_true)`/`sum(n_solic)`) %>%
                                 rename(date = datahora_solic_3_hour,n_solic =`sum(n_solic)`,n_true =  `sum(n_true)`)

```


```{r, animation.hook='gifski', echo=FALSE, warning=FALSE, message=FALSE, fig.align = 'center'}
dt_nteste <- sdata[sdata$ocorr_solic %in% os_dt,] %>% group_by(year(data_solic), date(data_solic), ocorr_solic) %>% 
                                          summarise(n_solic = n(), C = mean(match)) %>% 
                                          filter(`year(data_solic)` >= 2005, ocorr_solic == "DESLIZAMENTO DE TERRA") 

dt_nteste <- dt_ts
for (i in seq(1,50,1)){
              plot1 <- dt_nteste[dt_nteste$n_solic >= i,] %>% ggplot() + geom_histogram(aes(x=C)) + 
                                                             xlim(0,1) + ylim(0,50) +
                                                             geom_text(x=0, y=50, size=5,hjust = 0, label= paste0("n de corte = ", i))  + labs(title = "Histograna")
                                                             #geom_text(x=0, y=48, size=8,hjust = 0, label= paste0("p-valor = ", nteste[nteste$n_sol == i,]$p_value)) + 
                                                             #geom_text(x=0, y=46, size=8,hjust = 0, label= paste0("média = ", nteste[nteste$n_sol == i,]$media)) + 
                                                             #geom_text(x=0, y=44, size=8,hjust = 0, label= paste0("Desvio-padrão = ", nteste[nteste$n_sol == i,]$dp)) 
              plot2 <- dt_nteste[dt_nteste$n_solic >= i,] %>% ggplot() + geom_boxplot(aes(x=C)) + coord_flip() + xlim(0,1) + labs(title = "Boxplot")
              plot3 <- dt_nteste[dt_nteste$n_solic >= i,] %>% ggplot(aes(sample = C)) + stat_qq() + ylim(0,1) + xlim(-3,3)+  stat_qq_line() + labs(title = "Gráfico Quantil-quantil") 
              print((plot1 | plot2)/ plot3)}

```

O Histograma aponta que a distribuição se aproxima do formato de "sino" à medida que aumentamis o n de corte, o que induz à idaia da normalidade dos dados. 
Da mesma forma, o boxplot e o gráfico quantil-quantil - que relaciona os quantís de uma amostra normal teórica com os quantís dos dados estudados - apontam para uma distribuição normal a partir de um número mínimo de solicitações por dia (n de corte). 

Existindo indícios visuais, realizamos o teste estatístico de Shapiro-Wilk e calculamos um valor mínimo de solicitações por dia para a partir de quanto a amostra pode ser considerada normalmente distribuida. 

O teste parte da hipótese nula Ho que considera a distribuição dos dados como normal. Se o valor de significância obtido no teste for menor que 0.05, devemos descartar a hipótese nula. Em outras palavras, se o p-valor (valor de significâncial) > 0.05, a nossa distribuição não é normal. 

```{r, echo=FALSE, warning=FALSE, message=FALSE}


nteste <- data.frame(n_sol = seq(1, 268,1), n_C = 0, p_value =  0,media = 0, dp = 0)

 for (i  in nteste$n_sol) {
  z <- dt_nteste[dt_nteste$n_solic >= i,]$C
  nteste[nteste$n_sol == i,]$n_C <- length(z)
  nteste[nteste$n_sol == i,]$p_value <- ifelse(nteste[nteste$n_sol == i,]$n_C >= 3, shapiro.test(z)$p.value, 0)
  nteste[nteste$n_sol == i,]$media <- mean(z)
  nteste[nteste$n_sol == i,]$dp <- sd(z)
  }

nteste %>% filter(n_sol <= 50) %>%   
  ggplot() + geom_line(aes(x=n_sol, y = p_value), size = 1) + geom_hline(yintercept = 0.05, color = "red")+ 
             labs(title = " Valor de significância (p-valor) por n de corte",
                 x="n de corte",
                 y="p-valor")

min(filter(nteste, p_value >= 0.05)$n_sol)
max(filter(nteste, p_value >= 0.05)$n_sol)
nteste[nteste$p_value == max(nteste$p_value),]$n_sol
nteste[nteste$p_value == max(nteste$p_value),]$p_value
```


#### Canal de abertura

Sendo C uma métrica de verdadeiro-positivos, ou uma taxa de acertos, podemos apresentar FP = 1- C como uma métrica complementar que mede a taxa de falso-positivos (erros na indicação do tipo de ocorrência) na nossa base de dados.

Estudar a variação de FP de acordo com a forma como as solicitações entram no sistema pode nos dar uma dimensão da qualidade da triagem feita pelos canais de atendimento. Espera-se que o atendente seja capaz de ouvir o relato do cidadão e registrá-lo no sistema de forma concisa, captando os detalhes cruciais e fornecendo aos setores responsáveis pelo roteiro de vistoria informções confiáveis para definir a prioridade de atendimento. 

Para as análises a seguir, serão consideradas as ocorrências de _AMEAÇA DE DESLIZAMENTO_ e _DESLIZAMENTO DE TERRA_, dada a sua relevância na rotina do órgão e sua homogeneidade durante o periíodo analisado. 

Sob essa perspectiva, analisamos a hipótese, que é um senso comum dentro da CODESAL: _"Desde que saiu da sede do órgão, em 2015, a qualidade do atendimento 199 caiu"_. Essa afirmação parte da premissa que, enquanto na sede, os atendentes do 199 poderiam ser melhor orientados pelos técnicos, podendo tirar dúvidas e receber correções imediatas. 

Além disso, os atendentes do Call Center não desenvolvem uma especialiação no atendimento de Defesa Civil, uma vez que recepcionam também chamados para outras Secretarias. É rezoável considerar, então, que o atendimento presencial da CODESAL, aqui entitulado _PESSOALMENTE_ deve apresentar una taxa de erro no mínimo menor que o atendimento via 199. 

Afirmação 1: A taxa de erro do atendimento 199 deve aumentar a partir de 2015.
Afirmação 2: A taxa de erro do atendimento presencial (PESSOALMENTE) é menor que a do atendimento 199. 


O gráfico abaixo descreve a variação da taxa de erros (FP) dos canais de atendimento com o passar dos anos.  
```{r, echo=FALSE, warning=FALSE, message=FALSE}

dos_os <-sdata[sdata$ocorr_solic %in% os_dt & sdata$desc_orig_solic %in% c("199", "PESSOALMENTE"),] %>% group_by(year(data_solic), desc_orig_solic) %>% 
                                                                                                        summarise(n = mean(match)) 

dos_os %>% #filter(desc_orig_solic == "199") %>% 
           ggplot() + geom_line(aes(x = `year(data_solic)`, y = (1-n), colour = as.factor(desc_orig_solic)), size = 1.2) +
                                         coord_cartesian(ylim = c(0, 1)) +   
                                         scale_x_continuous(breaks = seq(2005,2019, 2))+
                                         theme(legend.position = "bottom", legend.box = "horizontal")+
                                          labs(title = "Taxa de erro, falso-positivo (FP), para solicitações abertas via 199.",
                                               subtitle = "",
                                              caption = "Período analisado: 07/05/2020 a 31/12/2019", 
                                              x = "Ano",
                                              y = "FP",
                                             colour = "Canal de aberura")  +
                    annotate(geom = "curve", x = 2015.4, y = 0.6, xend = 2015, yend = 0.5, curvature = .01, arrow = arrow(length = unit(2, "mm"))) +
                    annotate(geom = "text", x = 2015.4, y = 0.65, label = "Saída do 199 da sede da CODESAL", hjust = "center") 
                    #geom_point(aes(x=2015, y=0.465)) +
                    #theme(legend.position = "none")

```

As taxas de erra do 199 e do atendimento presencial apresentam comportamento relativamente regular até 2015, sobrepondo-se em determinados momentos e alternando em outros. É possivel observar que a taxa de falsos-positivos do 199 cai a partir de 2014 e continua em queda depois de 2015, quuando esse atendimento sai da sede da CODESAL. Já o FP do atendimento presencial cai significativamente a partir de 2015, chegando no patamar dos 25%. Contudo, ambas as taxas voltam a convergir em 2019 para um valor comum. Tal comportamento aponta que o indicador é influenciado por outro fenômeno, externo à essa análise inical. 

```{r, echo=FALSE, warning=FALSE, message=FALSE}
dos_os_2 <- sdata[sdata$ocorr_solic %in% os_dt & sdata$desc_orig_solic %in% c("199", "PESSOALMENTE"),] %>% group_by(year(data_solic),ocorr_solic, desc_orig_solic) %>% 
                                                                                                        summarise(n = mean(match)) 


dos_os_2 %>% ggplot() + geom_line(aes(x = `year(data_solic)`, y = (1-n), colour = as.factor(desc_orig_solic)), size = 1.2) +
                                          facet_wrap(~ocorr_solic)+
                                          coord_cartesian(xlim =c(2005, 2019), ylim = c(0, 1)) +   
                                         scale_x_continuous(breaks = seq(2005,2019, 2))+
                                         theme(legend.position = "bottom", legend.box = "horizontal")+
                                          labs(title = "Taxa de erro, falso-positivo (FP), por tipo de ocorrência. ",
                                              caption = "Período analisado: 07/05/2020 a 31/12/2019", 
                                              x = "Ano",
                                              y = "FP",
                                              colour = "Tipo de ocorrência") 
```








